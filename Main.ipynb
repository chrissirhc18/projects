{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 10)\n",
      "['Brazilian Tinamou' 'Red-legged Tinamou' 'Yellow-legged Tinamou'\n",
      " 'Black-capped Tinamou' 'Thicket Tinamou' 'Variegated Tinamou'\n",
      " \"Bartlett's Tinamou\" 'Small-billed Tinamou' 'Tataupa Tinamou'\n",
      " 'Red-winged Tinamou' 'Andean Tinamou' 'White-bellied Nothura'\n",
      " 'Spotted Nothura' 'Dwarf Tinamou' 'Orange-footed Scrubfowl'\n",
      " 'Plain Chachalaca' 'Little Chachalaca' 'Band-tailed Guan' 'Andean Guan'\n",
      " 'Rusty-margined Guan']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1.1 Read the CSV\n",
    "df = pd.read_csv('BirdsVoice.csv')\n",
    "\n",
    "# 1.2 Compute total recordings per species\n",
    "counts = df['common_name'].value_counts()\n",
    "top20 = counts.nlargest(20).index\n",
    "\n",
    "# 1.3 Filter to top 20 and reset index\n",
    "df = df[df['common_name'].isin(top20)].reset_index(drop=True)\n",
    "print(df.shape)            # ~600 × 10\n",
    "print(df['common_name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             filepath  duration_s\n",
      "0  audio/XC524787.mp3          57\n",
      "1  audio/XC521357.mp3           6\n",
      "2  audio/XC686176.mp3          53\n",
      "3  audio/XC643154.mp3         140\n",
      "4  audio/XC606110.mp3          42\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 2.1 Convert “M:SS” → seconds\n",
    "def length_to_seconds(x):\n",
    "    m, s = x.split(':')\n",
    "    return int(m) * 60 + int(s)\n",
    "\n",
    "df['duration_s'] = df['recording_length'].apply(length_to_seconds)\n",
    "\n",
    "# 2.2 Assume you’ve downloaded audio into ./audio/, named by xc_id:\n",
    "df['filepath'] = df['xc_id'].apply(lambda id: os.path.join('audio', f'{id}.mp3'))\n",
    "\n",
    "# 2.3 Quick check\n",
    "print(df[['filepath','duration_s']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 13) (120, 13) (120, 13)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 3.1 Label encoding\n",
    "label_map = {name:idx for idx,name in enumerate(top20)}\n",
    "df['label'] = df['common_name'].map(label_map)\n",
    "\n",
    "# 3.2 60/20/20 stratified split\n",
    "trainval, test = train_test_split(df, test_size=0.20, \n",
    "                                  stratify=df['label'], random_state=42)\n",
    "train, val   = train_test_split(trainval, test_size=0.25,  # 0.25×0.8 = 0.20\n",
    "                                 stratify=trainval['label'], random_state=42)\n",
    "\n",
    "print(train.shape, val.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def extract_mel(filepath):\n",
    "    try:\n",
    "        # Check if file exists first\n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"File not found: {filepath}\")\n",
    "            return None\n",
    "            \n",
    "        # Try loading with librosa\n",
    "        y, sr = librosa.load(filepath, sr=None, duration=None, mono=True)\n",
    "        \n",
    "        # Extract mel spectrogram\n",
    "        mel_spec = librosa.feature.melspectrogram(\n",
    "            y=y, \n",
    "            sr=sr, \n",
    "            n_mels=128,  # adjust as needed\n",
    "            fmax=8000    # adjust as needed\n",
    "        )\n",
    "        \n",
    "        # Convert to log scale\n",
    "        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "        \n",
    "        return mel_spec_db\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {filepath}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      xc_id                                           filepath  duration_s\n",
      "0  XC524787  audio/sound-of-114-species-of-birds-till-2022/...          57\n",
      "1  XC521357  audio/sound-of-114-species-of-birds-till-2022/...           6\n",
      "2  XC686176  audio/sound-of-114-species-of-birds-till-2022/...          53\n",
      "3  XC643154  audio/sound-of-114-species-of-birds-till-2022/...         140\n",
      "4  XC606110  audio/sound-of-114-species-of-birds-till-2022/...          42\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 2.1 Convert “M:SS” → seconds\n",
    "def length_to_seconds(x):\n",
    "    m, s = x.split(':')\n",
    "    return int(m) * 60 + int(s)\n",
    "\n",
    "df['duration_s'] = df['recording_length'].apply(length_to_seconds)\n",
    "\n",
    "# 2.2 Build filepaths in your nested audio folder\n",
    "#    (adjust the folder name if yours differs)\n",
    "audio_dir = os.path.join('audio',\n",
    "                         'sound-of-114-species-of-birds-till-2022')\n",
    "\n",
    "df['filepath'] = df['xc_id'].apply(\n",
    "    lambda xc_id: os.path.join(audio_dir, f\"{xc_id}.mp3\")\n",
    ")\n",
    "\n",
    "# 2.3 Quick sanity check\n",
    "print(df[['xc_id', 'filepath', 'duration_s']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: audio/sound-of-114-species-of-birds-till-2022/XC66646.mp3\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m     y = tf.keras.utils.to_categorical(y, num_classes=\u001b[38;5;28mlen\u001b[39m(label_map))\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m X_train, y_train = \u001b[43mbuild_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m X_val,   y_val   = build_dataset(val)\n\u001b[32m     15\u001b[39m X_test,  y_test  = build_dataset(test)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mbuild_dataset\u001b[39m\u001b[34m(df_subset)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m df_subset.iterrows():\n\u001b[32m      6\u001b[39m     feat = extract_mel(row[\u001b[33m'\u001b[39m\u001b[33mfilepath\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     X.append(\u001b[43mfeat\u001b[49m\u001b[43m[\u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnewaxis\u001b[49m\u001b[43m]\u001b[49m)                \u001b[38;5;66;03m# (128, T, 1)\u001b[39;00m\n\u001b[32m      8\u001b[39m     y.append(row[\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      9\u001b[39m X = np.stack(X, axis=\u001b[32m0\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def build_dataset(df_subset):\n",
    "    X, y = [], []\n",
    "    for _, row in df_subset.iterrows():\n",
    "        feat = extract_mel(row['filepath'])\n",
    "        X.append(feat[..., np.newaxis])                # (128, T, 1)\n",
    "        y.append(row['label'])\n",
    "    X = np.stack(X, axis=0)\n",
    "    y = tf.keras.utils.to_categorical(y, num_classes=len(label_map))\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = build_dataset(train)\n",
    "X_val,   y_val   = build_dataset(val)\n",
    "X_test,  y_test  = build_dataset(test)\n",
    "\n",
    "input_shape = X_train.shape[1:]  # e.g. (128, ~216, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking first few file paths:\n",
      "audio/sound-of-114-species-of-birds-till-2022/XC66646.mp3 - Exists: False\n",
      "audio/sound-of-114-species-of-birds-till-2022/XC451828.mp3 - Exists: False\n",
      "audio/sound-of-114-species-of-birds-till-2022/XC221871.mp3 - Exists: False\n",
      "audio/sound-of-114-species-of-birds-till-2022/XC500229.mp3 - Exists: False\n",
      "audio/sound-of-114-species-of-birds-till-2022/XC529057.mp3 - Exists: False\n"
     ]
    }
   ],
   "source": [
    "# Debug your file paths\n",
    "print(\"Checking first few file paths:\")\n",
    "for i, row in train.head().iterrows():\n",
    "    filepath = row['filepath']\n",
    "    exists = os.path.exists(filepath)\n",
    "    print(f\"{filepath} - Exists: {exists}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=input_shape),\n",
    "    layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(len(label_map), activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    batch_size=32,\n",
    "    epochs=30,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)]\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
